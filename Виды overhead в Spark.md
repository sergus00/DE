| Вид overhead                                          | Что это                                                                                                 | Откуда берётся                                   | Симптомы, если мало/много                                                  | Как уменьшить                                                                                       |
| ----------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |
| **Memory Overhead** (`spark.executor.memoryOverhead`) | Доп. память **вне heap** (off-heap) для shuffle, сетевых буферов, PySpark-процессов, нативных библиотек | Сетевые буферы Netty, Arrow, JNI, Python-воркеры | Ошибки `OutOfMemoryError: Direct buffer memory`, падения при shuffle/joins | Увеличить `spark.executor.memoryOverhead` до max(384 MB, 10–15% от heap), оптимизировать shuffle    |
| **Network / Shuffle Overhead**                        | Время и ресурсы на сериализацию, передачу и десериализацию данных между executors                       | Shuffle, широкие join’ы, groupBy, repartition    | Высокий Shuffle Read/Write Time в Spark UI, перегрузка сети                | Меньше shuffle (broadcast для маленьких таблиц, фильтры до join), увеличить партиции до ~128–512 МБ |
| **Scheduling Overhead**                               | Задержки между готовностью задачи и её запуском                                                         | Много мелких задач, узкое место в драйвере       | Scheduler Delay высок в Spark UI, CPU простаивает                          | Уменьшить число задач (coalesce, оптимизация партиций), увеличить ресурсы драйвера                  |
| **Garbage Collection Overhead**                       | Время, которое JVM тратит на сборку мусора вместо вычислений                                            | Большой heap, много объектов, перекос данных     | GC Time > 10–15% в Spark UI, длинные stop-the-world паузы                  | Меньше heap на executor, меньше cores per executor, columnar форматы, G1GC                          |
